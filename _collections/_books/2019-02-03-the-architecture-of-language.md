---
layout: post
title:  "The Architecture of Language"
author: Noam Chomsky
categories: [booknotes]
tags: [language]
permalink: /the-architecture-of-language
image: https://images-na.ssl-images-amazon.com/images/I/41vgwOA%2BAZL.jpg
description: "How to discover the structure of the language, the variations of our languages and how is it used in our brain."
rating: 1
---

> I am torn by two temptations. [...] One concerns language as a biological organ- it is pretty clear that it is [...]. The other concerns human life and its problems and the use of language as a technique of exploitation and so on. But in that second domain there is nothing known of any depth, to my knowledge.
>
> -- __The Architecture of Language__

[Noam Chomsky](https://en.wikipedia.org/wiki/Noam_Chomsky) is the most creative and famous author on language and mind. No compilation about language is complete without Chomsky's point of view.

![What does a chimp say?](https://www.smbc-comics.com/comics/1445793036-20151025.png)

Apart from being one of the most cited scholars in history, and having [a chimp named after him](https://www.theguardian.com/film/2011/jul/24/project-nim-chimpsky-chimpanzee-language), Noam Chomsky has been addressing a vast range of audiences across the world. The one that concerns us took place in India in 1996, where he made a series of lectures, of which only one concerned his work on language and mind. That lecture took about 90 minutes, and it was meant to be a general public lecture as well as a means for addressing professional linguists. Thus, he covered much ground within the timespan given, covering both the philosophical issues and his technical work.

Like we did in Taleb's [Skin in the Game](/skin-in-the-game) and Wittgenstein's [Tractatus](/tractatus-logico-philosophicus), these notes aim at covering as much of the author's ideas as possible, leaving the details for the curious explorer, and start with a [not-so-brief introduction to Chomsky's ideas](https://www.youtube.com/watch?v=1umiaNjOinE#t=1h38m07s).

Only by the breadcrumbs left on the ground can we follow the path of the masters.

> Science is a very strange activity. It only works for simple problems. [...] The idea that deep scientific analysis tells you something about problems of human beings and our lives and our inter-relations with one another and so on is mostly pretence.
>
> -- __The Architecture of Language__

The first part of the lecture concerns the area of human language, and Chomsky outlines some phases of the research on language that had led to what eventually came to be known as the [Minimalist Program](https://mitpress.mit.edu/books/minimalist-program).

Let's start with some assumptions.

1. __There is some part of the mind-brain dedicated to the knowledge and use of language__

    We'll call it 'language faculty'.

2. __This language faculty is an actual species property__

    It's common ground for humans, with little variations across the species, and it's unique to human beings.

    > It is almost as if there was some higher primate wandering around a long time ago and some random mutation took place, maybe after some strange cosmic ray shower, and it reorganized the brain, implanting a language organ in an otherwise primate brain.
    >
    > -- __The Architecture of Language__


3. __This language faculty includes at least a cognitive system that stores information__

    This information can change through life; a speaker of Hindi is not a speaker of English, so something has changed from a common state.

4. __Like height, the different languages spoken by humans are only different in a superficial fashion, and largely determined by a natural common language faculty__

    Nurture is too limited to do anything other than shaping an already existing common form.

    > It is interesting that this conclusion is considered very controversial [...], and trivial in the case of all other growth processes, say the fact that an embryo grows arms, not wings. [...]
    >
    > The fact that people don't accept the argument is due to the residues of a sort of irrational form of dualism which one ought to overcome.
    >
    > -- __The Architecture of Language__

5. __Each linguistic expression is some collection of properties__

    We grow our language from a set of expressions; this is what we call 'generative grammar'.

6. __The performance system falls into two categories: sound and meaning__

    Like we discussed in [How to Read a Book](/how-to-read-a-book), 'words' and 'terms'.

    > The systems that access representations of meaning [...], which are mostly mysterious, are the systems that access certain aspects of expressions to enable you to do the things you do with language: express your thoughts, talk about the world, whatever it may be.
    >
    > [This dualism means that] an expression has to have two kinds of symbolic objects as its parts. These objects can be regarded as a kind of an interface between the language faculty and other systems of the mind-brain.
    >
    > -- __The Architecture of Language__

We have now laid down the terms of the discussion. The point of the lecture is now the following: we want to discover the 'architecture', the structure of the language, and how we think using it.

This study has the form of one of the natural sciences; it is unusual because we are concerned with human faculties, rather than the structure of the Universe, and human faculties are mostly beyond the level of serious studies.

How language relates to other aspects of the world? How can the properties of the language faculty be realised in the physical world? How do expressions represent reality, words refer to terms?

These questions are radically misconceived. In the 1950s, at the origins of modern generative grammar, problems within this range began to be examined more seriously. By then, the theory of computer science and other branches of mathematics have dealt with questions like 'how can you have infinite use of finite means?', and answered some aspects of these questions, allowing the generative grammar to flourish.

It quickly became clear that there was a conflict between the double goal of linguistic theory. On one side, you want *descriptive adequacy*: characterise the possible human grammars used to speak, with far more intricacies and complexities that dictionaries lead to believe.

On the other hand, you also want *explanatory adequacy*: the child’s ability to select a descriptively adequate grammar given the data they receive. So languages must somehow be extremely simple and very much like one another, otherwise language acquisition is a miracle.

> Adjectives in English absolutely have to be in this order: opinion-size-age-shape-colour-origin-material-purpose Noun. So you can have a lovely little old rectangular green French silver whittling knife. But if you mess with that word order in the slightest you’ll sound like a maniac. It’s an odd thing that every English speaker uses that list, but almost none of us could write it out.
>
> -- __Mark Forsyth__, [The Elements of Eloquence](https://www.amazon.com/Elements-Eloquence-Secrets-Perfect-Phrase/dp/042527618X/ref=sr_1_1?s=amazon-elements&srs=8514636011&ie=UTF8&qid=1549118372&sr=8-1&keywords=elements+of+eloquence)

That looks like a flat contradiction. The general approach was the natural one: try to abstract general principles, take them to be properties of the language faculty itself, and try to show that the residue is much less complex and varied than it looks. English, Hindi, French, Spanish, they all share a common structure that is innate to humans, and we shape the way we speak with the data we are exposed to, so that English kids say 'cheese' and French kids say '*fromage*'.

This came to be known as the 'principles and parameters approach'. The principles hold across languages and constructions; the parametric variation is a finite space, which means that there are only a finite number of possible languages.

Unlike the theories that came before, it assume that there were no grammatical constructions at all. Not that they don't exist in Japanese, or German, but in the sense that they are all just 'taxonomic', not 'biological'. They just happened to be the way these languages are spoken, but are a consequence of the application of the parameters over the common principles.

This approach is not a theory, but a theoretical framework, a way of thinking about language. It's the first one that proposes a way to resolve the tension between explanatory and descriptive adequacy.

> When you discover the principles, you see that [languages] are really quite the same and that the differences among them are quite superficial.
>
> -- __The Architecture of Language__

It is now possible to raise new questions about the nature of the language; that's where the Minimalist Program comes along. How good language is to the boundary conditions imposed by the architecture of the mind?

> The language organ is inserted into  a system of mind that has a certain architecture; it has interface relations with that system. It connects to them. The assumption is that there are the two interfaces that I mentioned. Those interfaces impose some conditions on what the system must be like. How good a solution is language to the conditions imposed by those external assumptions?
>
> -- __The Architecture of Language__

So, the mythical random 'cosmic ray shower' that caused language faculty to be installed in that primate is capable of providing an infinity of expressions that can be accessed by the already existing performance systems.

On one condition: __to be usable, the expressions have to be legible by the outside systems__.

This helps explain in more realistic terms our second assumption: language is unique to humans because only in humans the language faculty came to meet the legibility conditions. Higher primates actually have something like a human language, but they just have no access to it. Like other animals, they are left with grumps and noises and gestures to frustratingly express what they are meaning, without conveying a code that can be interpretable in a one-to-one way with human language.

How well do the laws of language come to design a solution to the 'engineering problem' posed by the legibility conditions on expressions?

Well, not bad, but not perfect either.

> Two people can be using the same word, meaning different things, yet continue the conversation. That's fine for coffee, but not when making decisions.
>
> -- __[Skin in the Game](/skin-in-the-game)__
>
> Usually, and unfortunately, people discuss all in words, like their reading. They don’t speak terms.
>
> -- __[How to Read a Book](/how-to-read-a-book)__
>
> The words democracy, socialism, freedom, patriotic, realistic, justice, have each of them several different meanings which cannot be reconciled with one another. In the case of a word like democracy, not only is there no agreed definition, but the attempt to make one is resisted from all sides.
>
> -- __[Politics and the English Language](/politics-and-the-english-language)__

Take the sentence 'John had a book stolen'. It can be interpreted that:

1. Someone stole John's book

2. John had someone steal a book

3. John had almost succeeded in stealing a book

Speaking will require that the expression has a temporal order, phonetic properties, rhythmic patterns, an so on. If an expression doesn't have those things, we won't be able to say it out loud, because our language faculty won't be able to 'read' it. But the fact that 'John had a book stolen' is ambiguous is the consequence of a suboptimal design of the language.

So even us human beings, with our unique language capabilities, still struggle to convey knowledge unambiguously.

> Whatever the sound-meaning relations are, they are something over and above the property of being accessible to the several performance systems, the property of having the right kind of phonetic and semantic representations, interface representations.
>
> -- __The Architecture of Language__

We are questioning whether knowing about the legibility conditions sheds light onto the sound-meaning relations: the architecture of language could be the gateway to understanding how we think. By doing so, we face two problems:

1. You have to show that there are no linguistic levels apart from the interface levels themselves.

    Other levels are not motivated by legibility conditions and have no reason to be there. Using [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor), the simplest explanation must prevail.

2. You have to show that a lexical item contains no features other than those that are interpreted at the interface.

    That means there are no indices and no [X-bar theory](https://en.wikipedia.org/wiki/X-bar_theory).

3. You have to show that there are no structural relations other than those that are forced by the legibility conditions.

    That means there is no [Binding theory](https://en.wikipedia.org/wiki/Binding_(linguistics)).


> Those of you who are familiar with the technical literature [...] are aware that there is a ton of empirical evidence to support the opposite conclusion on every single point that I mentioned.
>
> -- __The Architecture of Language__

Now, language isn't perfect. One of the most dramatic imperfections is the property of *displacement*, or feature movement: the fact that phrases are interpreted as if they have moved relative to where they are supposed to be based on basic structure rules.

> For example, take the sentence 'the book seems to have been stolen'. What is the relation between 'book' and 'steal'? You understand that to be the same relation as it is in 'John stole the book', [...] but there isn't that relationship in 'the book seems to have been stolen'.
>
> -- __The Architecture of Language__

In early generative grammar, it was assumed that the property is captured by an operation that displaced the phrase from its position of interpretation. The more complex assumption is that there is a compound operation: attaching the phrase somewhere else, and deleting the original.

Why would you hear the phrase just once, then? Because it's simpler to say it. We use pronouns to reduce the cognitive overload and the complexity of a sentence, and that is why I didn't need to write 'Human beings' at the beginning of this one, but instead a simple 'We' sufficed.

But as far as the mind is concerned, the phrase is there. When I say 'We', I meant 'Human beings', and in your head, you understood that. Or, at least, I assumed that you did.

But here comes a strange consequence. If we assume that certain features of lexical items are not legible, and are not there, then the uninterpretable features within a word have to be erased. Take 'books'. In English, it is written the same way if it is in Nominative case ('Books are cheap') or Accusative case ('I read books'), so the property of structural case is not legible there; it must be defined somewhere else.

> It might be that this is no imperfection at all, but rather an optimal way of satisfying an externally imposed legibility condition.
>
> -- __The Architecture of Language__

The other operation needed is one that takes two linguistic objects that have already been formed by the recursive procedures of generation, and constructs a larger one from them. So if you start from having 'the man' and 'stole the book', you can form 'the man stole the book'.

> On minimalist assumptions (that is perfection assumptions), the generation of expressions should involve nothing more than these two operations- feature movement to erase illegible features, and merger- taking two constructions and putting them together.
>
> -- __The Architecture of Language__

If that is true, then differences across languages are going to be a consequence of how uninterpretable features are represented, a consequence of the narrow class of lexical properties, restricted by the condition of legibility: differences are, thus, only superficial.

> If such conclusions can be established over a broad range, we can pursue the basic quest of the Minimalist Program- to try to show that the universal properties themselves are explicable on principles of optimal design, given the requirement of legibility at the interface.
>
> [...] If some version of this programme works out, we will have a picture of language that is surprising for a biological system.
>
> -- __The Architecture of Language__
